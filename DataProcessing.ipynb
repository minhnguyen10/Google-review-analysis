{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d2c8523-2dc4-437e-9544-d03cccbf33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "from urllib.parse import urlsplit, parse_qsl\n",
    "import pandas as pd\n",
    "import json\n",
    "import errno\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "from config import API_KEY_SER, coop_list, coop_ids "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec8fd9-b09b-44e7-823f-0db4101eafef",
   "metadata": {},
   "source": [
    "### Overview: \n",
    "In this project, I gathered an Electricity Co-op (Co-op A) Google Revews using serpapi, processed the data (in a seperate notebook), and analyzed it. In this notebook, I will get the data from serpapi, process the data, and store it in a data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dc5db7-5ea7-4f4e-8265-09b0021d0b89",
   "metadata": {},
   "source": [
    "## 1. Pull Data Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8beab607-e3c3-4cb6-b474-8920a8fb2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data(data_id):\n",
    "    params = {\n",
    "      \"api_key\": API_KEY_SER,                   # your api key\n",
    "      \"engine\": \"google_maps_reviews\",                    # serpapi search engine\n",
    "      \"hl\": \"en\",                                         # language of the search\n",
    "      \"sort_by\":\"newestFirst\",\n",
    "      \"data_id\": data_id  # place id data located inside Google Maps Place URL: located inside `data=` query parameter. \n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "\n",
    "    reviews = []\n",
    "\n",
    "    page_num = 0\n",
    "    while True:\n",
    "        page_num += 1\n",
    "        results = search.get_dict()\n",
    "\n",
    "        print(f\"Extracting reviews from {page_num} page.\")\n",
    "\n",
    "        if not \"error\" in results:\n",
    "            for result in results.get(\"reviews\", []): # return an empty list [] if no reviews from the place\n",
    "                reviews.append({\n",
    "                    \"page\": page_num,\n",
    "                    \"name\": result.get(\"user\").get(\"name\"),\n",
    "                    \"link\": result.get(\"user\").get(\"link\"),\n",
    "                    \"thumbnail\": result.get(\"user\").get(\"thumbnail\"),\n",
    "                    \"rating\": result.get(\"rating\"),\n",
    "                    \"date\": result.get(\"date\"),\n",
    "                    \"snippet\": result.get(\"snippet\"),\n",
    "                    \"images\": result.get(\"images\"),\n",
    "                    \"local_guide\": result.get(\"user\").get(\"local_guide\"),\n",
    "                    # other data\n",
    "                })\n",
    "        else:\n",
    "            print(results[\"error\"])\n",
    "            break\n",
    "\n",
    "        if results.get(\"serpapi_pagination\") is not None:\n",
    "            results.get(\"serpapi_pagination\").get(\"next\")\n",
    "            if results.get(\"serpapi_pagination\").get(\"next\") and results.get(\"serpapi_pagination\").get(\"next_page_token\"):\n",
    "                # split URL in parts as a dict and update search \"params\" variable to a new page that will be passed to GoogleSearch()\n",
    "                search.params_dict.update(dict(parse_qsl(urlsplit(results[\"serpapi_pagination\"][\"next\"]).query)))\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(reviews)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1707f7ae-d324-4a62-9950-96bba034152e",
   "metadata": {},
   "source": [
    "## 2. Estimate Date methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c1682bd-8631-4725-a6e8-4f5270d4abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_estimated_date(date):\n",
    "#     today = datetime.today()\n",
    "#     today_date_object = datetime.strptime(today, '%m-%d-%Y').date()\n",
    "    today_date_object = datetime.today()\n",
    "    if \"day\" in date:\n",
    "        if \"a \" in date:\n",
    "            day_ago  = 1\n",
    "        else:\n",
    "            day_ago = int(date.split()[0])\n",
    "        estimated_review_date = today_date_object - timedelta(days=day_ago)\n",
    "    elif \"week\" in date:\n",
    "        if \"a \" in date:\n",
    "            week_ago  = 1\n",
    "        else:\n",
    "            week_ago = int(date.split()[0])\n",
    "        estimated_review_date = today_date_object - relativedelta(weeks=week_ago)\n",
    "    elif \"month\" in date:\n",
    "        if \"a \" in date:\n",
    "            month_ago  = 1\n",
    "        else:\n",
    "            month_ago = int(date.split()[0])\n",
    "        estimated_review_date = today_date_object - relativedelta(months=month_ago)\n",
    "    else:\n",
    "        if \"a \" in date:\n",
    "            year_ago  = 1\n",
    "        else:\n",
    "            year_ago = int(date.split()[0])\n",
    "        estimated_review_date = today_date_object - relativedelta(years=year_ago)\n",
    "\n",
    "    return estimated_review_date\n",
    "\n",
    "def find_year(date):\n",
    "    estimated_review_date = find_estimated_date(date)\n",
    "    year = estimated_review_date.year\n",
    "    # Extract year\n",
    "    return year\n",
    "\n",
    "def apply_find_year(row):\n",
    "    return find_year(row['date'])\n",
    "\n",
    "def find_month(date):\n",
    "    estimated_review_date = find_estimated_date(date)\n",
    "    # Extract month\n",
    "    month = estimated_review_date.month\n",
    "    return month\n",
    "\n",
    "def apply_find_month(row):\n",
    "    return find_month(row['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed039a90-8df2-4f0a-bd09-aa123c7f4330",
   "metadata": {},
   "source": [
    "## 3. Clean data method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7ae5164-6e0e-4cc3-ab68-a3ba3b76ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can add year and month column, drop column link, thumbnail, images, local_guide\n",
    "def clean_data(data):\n",
    "    data[\"Year\"] = data.apply(apply_find_year, axis=1) \n",
    "    data = data.rename(columns={\"name\": \"Customer Name\", \"rating\": \"Rating\",\"snippet\":\"Review\"})\n",
    "    final_data = data[[\"Customer Name\",\"Year\",\"Rating\",\"Review\"]].copy()\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd00253c-8877-4c0b-9356-cceee043fb8b",
   "metadata": {},
   "source": [
    "## 4. Store data method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e75448fc-be91-4fa5-b560-93f50a4a9f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exists(path):\n",
    "    return os.path.exists(path)\n",
    "\n",
    "def makedir_exist_ok(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as e:\n",
    "        if e.errno == errno.EEXIST:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "    return\n",
    "\n",
    "#Save data\n",
    "def save(input, path):\n",
    "    dirname = os.path.dirname(path)\n",
    "    makedir_exist_ok(dirname)\n",
    "    # print(dirname)\n",
    "    input.to_csv(path,index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b92eca-26f8-4b83-97d3-ce715cb2527c",
   "metadata": {},
   "source": [
    "## 5. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da313b96-d7d3-4377-a8ee-edc908c19cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    new_pull = False\n",
    "    new_process = True\n",
    "    root = os.path.join('data')\n",
    "    raw_folder =  os.path.join(root, 'raw')\n",
    "    processed_folder =  os.path.join(root, 'processed')\n",
    "    for coop in coop_list:\n",
    "        data_id = coop_ids[coop]\n",
    "        raw_data_path = os.path.join(raw_folder, '{}_raw.csv'.format(coop))\n",
    "        processed_data_path = os.path.join(processed_folder, '{}_processed.csv'.format(coop))\n",
    "        if new_pull:\n",
    "            raw_data = pull_data(data_id)\n",
    "            #store raw data\n",
    "            save(raw_data,raw_data_path)\n",
    "        \n",
    "        if new_process:\n",
    "            #read raw data\n",
    "            raw_data_read = pd.read_csv(raw_data_path)\n",
    "            #process data\n",
    "            processed_data = clean_data(raw_data_read)\n",
    "            #strore processed data\n",
    "            save(processed_data,processed_data_path)\n",
    "        print(\"{} Data Processing Completed\".format(coop))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642dee3f-96a0-415a-a0be-72507c30f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
